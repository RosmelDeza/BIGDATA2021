{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f97722e2",
      "metadata": {
        "id": "f97722e2"
      },
      "source": [
        "# CURSO: MINERIA DE DATOS\n",
        "### ESTUDIANTE: ROSMEL URIEL DEZA CONDORI\n",
        "### CODIGO: 171058\n",
        "### TAREA: 5 Ejercicios de Pre-Procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047780d1",
      "metadata": {
        "id": "047780d1"
      },
      "source": [
        "## IMPORTAR LIBRERIAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49787a0b",
      "metadata": {
        "id": "49787a0b"
      },
      "outputs": [],
      "source": [
        "# Instalar el paquete findspark  para acceder a Spark desde cualquier entorno de trabajo Python.\n",
        "import findspark \n",
        "findspark.init()\n",
        "# Importar librerias BIGDATA\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd2c1ab",
      "metadata": {
        "id": "4bd2c1ab"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c10c271",
      "metadata": {
        "id": "1c10c271"
      },
      "source": [
        "## 1. ALGORITMO DE ESCALONAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d05a0d",
      "metadata": {
        "id": "67d05a0d",
        "outputId": "1d7a38cf-a5af-4df3-aad7-741fec427faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Funciones escaladas al rango: [0.000000, 1.000000]\n",
            "+--------------+--------------+\n",
            "|      features|scaledFeatures|\n",
            "+--------------+--------------+\n",
            "|[1.0,0.1,-1.0]|     (3,[],[])|\n",
            "| [2.0,1.1,1.0]| [0.5,0.1,0.5]|\n",
            "|[3.0,10.1,3.0]| [1.0,1.0,1.0]|\n",
            "+--------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Librerías necesarias para el escalonamiento \n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# Data de entrada\n",
        "dataFrame = spark.createDataFrame([\n",
        "    (0, Vectors.dense([1.0, 0.1, -1.0]),),\n",
        "    (1, Vectors.dense([2.0, 1.1, 1.0]),),\n",
        "    (2, Vectors.dense([3.0, 10.1, 3.0]),)\n",
        "], [\"id\", \"features\"])\n",
        "\n",
        "# Ingresamos parámetros para el MinMaxScaler\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "# Calcule estadísticas resumidas y genere MinMaxScalerModel\n",
        "scalerModel = scaler.fit(dataFrame)\n",
        "\n",
        "# Cambiar la escala de cada característica al rango [mínimo, máximo]\n",
        "scaledData = scalerModel.transform(dataFrame)\n",
        "print(\"Funciones escaladas al rango: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n",
        "scaledData.select(\"features\", \"scaledFeatures\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9001acf5",
      "metadata": {
        "id": "9001acf5"
      },
      "source": [
        "## 2. ALGORITMO DE NORMALIZACIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b577c3",
      "metadata": {
        "id": "50b577c3",
        "outputId": "ed118f69-a231-492a-c64a-272abb583d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalizando....\n",
            "+---+--------------+------------------+\n",
            "| id|      features|      normFeatures|\n",
            "+---+--------------+------------------+\n",
            "|  0|[1.0,0.5,-1.0]|    [0.4,0.2,-0.4]|\n",
            "|  1| [2.0,1.0,1.0]|   [0.5,0.25,0.25]|\n",
            "|  2|[4.0,10.0,2.0]|[0.25,0.625,0.125]|\n",
            "+---+--------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importamos la librerías a utilizar\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "#Crea dataframe\n",
        "dataFrame = spark.createDataFrame([\n",
        "    (0, Vectors.dense([1.0, 0.5, -1.0]),),\n",
        "    (1, Vectors.dense([2.0, 1.0, 1.0]),),\n",
        "    (2, Vectors.dense([4.0, 10.0, 2.0]),)\n",
        "], [\"id\", \"features\"])\n",
        "\n",
        "# Normaliza cada vector usando la Normalizer.\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
        "l1NormData = normalizer.transform(dataFrame)\n",
        "print(\"Normalizando....\")\n",
        "l1NormData.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dba31a0",
      "metadata": {
        "id": "5dba31a0"
      },
      "source": [
        "## 3. ALGORITMO DE BAG OF WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a39ca42",
      "metadata": {
        "id": "9a39ca42",
        "outputId": "67663962-0f1d-4ca2-d6b8-dce26bf6772a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+------+------------------+\n",
            "|Title|Month|Author|          Document|\n",
            "+-----+-----+------+------------------+\n",
            "|    a|  Jan|  John|This is a document|\n",
            "|    b|  Feb|  Mary|    A book by Mary|\n",
            "|    c|  Mar|  Luke| Newspaper article|\n",
            "|    d|  Apr|  Mark|              null|\n",
            "+-----+-----+------+------------------+\n",
            "\n",
            "+---------+-----+\n",
            "|    lower|count|\n",
            "+---------+-----+\n",
            "| document|    1|\n",
            "|       is|    1|\n",
            "|        a|    2|\n",
            "|     this|    1|\n",
            "|       by|    1|\n",
            "|     mary|    1|\n",
            "|     book|    1|\n",
            "|newspaper|    1|\n",
            "|  article|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importamos la librerías a utilizar\n",
        "from pyspark.sql.functions import explode, split, regexp_replace, col, lower\n",
        "#Data\n",
        "data = [\n",
        "    ['a', 'Jan', 'John', 'This is a document'],\n",
        "    ['b', 'Feb', 'Mary', 'A book by Mary'],\n",
        "    ['c', 'Mar', 'Luke', 'Newspaper article'],\n",
        "    ['d', 'Apr', 'Mark', None]\n",
        "]\n",
        "columns = ['Title', 'Month', 'Author', 'Document']\n",
        "#Creando un data frame df\n",
        "df = spark.createDataFrame(data, columns)\n",
        "#Mostrando el df\n",
        "df.show()\n",
        "#BOG\n",
        "df.select(explode(split(regexp_replace(\"Document\", \"[,.-]\", \" \"), \"\\s+\")).alias(\"word\"))\\\n",
        "    .groupby(lower(col(\"word\")).alias(\"lower\"))\\\n",
        "    .count()\\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aac88d",
      "metadata": {
        "id": "54aac88d"
      },
      "source": [
        "## 4. ALGORITMO DE N-GRAMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd8ab87",
      "metadata": {
        "id": "4fd8ab87",
        "outputId": "6118ab78-6837-44be-e1ff-4edefbba6dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------+\n",
            "|ngrams                                                            |\n",
            "+------------------------------------------------------------------+\n",
            "|[Hi I, I heard, heard about, about Spark]                         |\n",
            "|[I wish, wish Java, Java could, could use, use case, case classes]|\n",
            "|[Logistic regression, regression models, models are, are neat]    |\n",
            "+------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importamos la librerías a utilizar\n",
        "from pyspark.ml.feature import NGram\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "wordDataFrame = spark.createDataFrame([\n",
        "    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n",
        "    (1, [\"I\", \"wish\", \"Java\", \"could\", \"use\", \"case\", \"classes\"]),\n",
        "    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"neat\"])\n",
        "], [\"id\", \"words\"])\n",
        "\n",
        "ngram = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams\")\n",
        "\n",
        "ngramDataFrame = ngram.transform(wordDataFrame)\n",
        "ngramDataFrame.select(\"ngrams\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98337708",
      "metadata": {
        "id": "98337708"
      },
      "source": [
        "#### LECTURA DE DATOS PARA EL TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7d4d6b",
      "metadata": {
        "id": "1c7d4d6b"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.master(\"local[4]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223d41a3",
      "metadata": {
        "id": "223d41a3",
        "outputId": "8bbdaa4b-4b2a-444e-eab4-c0137659d8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------+------+\n",
            "|                                                                                              Review|Rating|\n",
            "+----------------------------------------------------------------------------------------------------+------+\n",
            "|nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advi...|     4|\n",
            "|ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, star...|     2|\n",
            "|nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroo...|     3|\n",
            "|unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown sh...|     5|\n",
            "|great stay great stay, went seahawk game awesome, downfall view building did n't complain, room h...|     5|\n",
            "|love monaco staff husband stayed hotel crazy weekend attending memorial service best friend husba...|     5|\n",
            "|cozy stay rainy city, husband spent 7 nights monaco early january 2008. business trip chance come...|     5|\n",
            "|excellent staff, housekeeping quality hotel chocked staff make feel home, experienced exceptional...|     4|\n",
            "|hotel stayed hotel monaco cruise, rooms generous decorated uniquely, hotel remodeled pacific bell...|     5|\n",
            "|excellent stayed hotel monaco past w/e delight, reception staff friendly professional room smart ...|     5|\n",
            "|poor value stayed monaco seattle july, nice hotel priced 100- 150 night not, hotel takes beating ...|     2|\n",
            "|nice value seattle stayed 4 nights late 2007. looked comparable hilton marriott westin area point...|     4|\n",
            "+----------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 12 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Leer el dataset tripavidsor_hotel.csv y mostrar 33 datos del dataset\n",
        "df = spark.read.csv(\"tripadvisor_hotel_reviews.csv\", header=True)\n",
        "df.show(n=12, truncate=100, vertical=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d40d87",
      "metadata": {
        "id": "f2d40d87"
      },
      "source": [
        "## 5. ALGORITMO DE **IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28bab02",
      "metadata": {
        "id": "b28bab02"
      },
      "source": [
        "La frecuencia inversa de documento es una medida de si el término es común o no, en la colección de documentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5026059d",
      "metadata": {
        "id": "5026059d",
        "outputId": "2d48ce32-9bf9-4feb-8a92-1d053ba2aba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------+---------------+\n",
            "|    Token|Token_in_all_documents_count|Documents_count|\n",
            "+---------+----------------------------+---------------+\n",
            "|    hotel|                       16325|          20491|\n",
            "|     room|                       14056|          20491|\n",
            "|      not|                       12124|          20491|\n",
            "|    staff|                       11528|          20491|\n",
            "|    great|                       11021|          20491|\n",
            "|     stay|                       10096|          20491|\n",
            "|     good|                        9280|          20491|\n",
            "|   stayed|                        8552|          20491|\n",
            "|       nt|                        8383|          20491|\n",
            "|    rooms|                        8341|          20491|\n",
            "| location|                        8172|          20491|\n",
            "|     just|                        7736|          20491|\n",
            "|    clean|                        7651|          20491|\n",
            "|     nice|                        7420|          20491|\n",
            "|      did|                        7207|          20491|\n",
            "|breakfast|                        7113|          20491|\n",
            "|       no|                        6818|          20491|\n",
            "|    night|                        6479|          20491|\n",
            "|  service|                        6232|          20491|\n",
            "|     time|                        6155|          20491|\n",
            "| friendly|                        5839|          20491|\n",
            "|      day|                        5781|          20491|\n",
            "|     food|                        5476|          20491|\n",
            "|     like|                        5329|          20491|\n",
            "|    place|                        5316|          20491|\n",
            "|  helpful|                        5057|          20491|\n",
            "|   really|                        4883|          20491|\n",
            "|    small|                        4847|          20491|\n",
            "|     walk|                        4643|          20491|\n",
            "|excellent|                        4424|          20491|\n",
            "|   little|                        4404|          20491|\n",
            "|     best|                        4265|          20491|\n",
            "| bathroom|                        4254|          20491|\n",
            "+---------+----------------------------+---------------+\n",
            "only showing top 33 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "idf_table = (\n",
        "    tf_table\n",
        "    .groupby('Token')\n",
        "    .agg(\n",
        "        {'Document_ID': 'count'}\n",
        "    )\n",
        "    .withColumnRenamed(\n",
        "        'count(Document_ID)',\n",
        "        'Token_in_all_documents_count'\n",
        "    )\n",
        "    .orderBy(\n",
        "        F.col('Token_in_all_documents_count').desc()\n",
        "    )\n",
        "    .limit(100)\n",
        "    .withColumn(\n",
        "        'Documents_count',\n",
        "        F.lit(df.count())\n",
        "    )\n",
        ")\n",
        "\n",
        "idf_table.show(n=33, truncate=True, vertical=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dccff7ed",
      "metadata": {
        "id": "dccff7ed"
      },
      "source": [
        "## 6. ALGORITMO DE TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf70c434",
      "metadata": {
        "id": "cf70c434"
      },
      "source": [
        "El tf-idf se calcula como:\n",
        "Un peso alto en tf-idf se alcanza con una elevada frecuencia de término (en el documento dado) y una pequeña frecuencia de ocurrencia del término en la colección completa de documentos. Como el cociente dentro de la función logaritmo del idf es siempre mayor o igual que 1, el valor del idf (y del tf-idf) es mayor o igual que 0. Cuando un término aparece en muchos documentos, el cociente dentro del logaritmo se acerca a 1, ofreciendo un valor de idf y de tf-idf cercano a 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b9c21c",
      "metadata": {
        "id": "01b9c21c",
        "outputId": "b894fc70-f9a2-46f0-a156-b473d6cc5c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+-----------------------+------------+----------------------------+---------------+\n",
            "|     Token|Document_ID|Token_in_document_count|Tokens_count|Token_in_all_documents_count|Documents_count|\n",
            "+----------+-----------+-----------------------+------------+----------------------------+---------------+\n",
            "|      room|          0|                      3|          86|                       14056|          20491|\n",
            "|    better|          1|                      2|         243|                        3244|          20491|\n",
            "|attractive|          6|                      1|          98|                        null|           null|\n",
            "|  positive|          6|                      1|          98|                        null|           null|\n",
            "| concierge|          7|                      2|          85|                        null|           null|\n",
            "|        nt|         10|                      2|          44|                        8383|          20491|\n",
            "|     clean|         12|                      1|          84|                        7651|          20491|\n",
            "|   concert|         12|                      1|          84|                        null|           null|\n",
            "|      stay|         15|                      2|         209|                       10096|          20491|\n",
            "|      desk|         16|                      6|         237|                        3192|          20491|\n",
            "|       bed|         19|                      1|         151|                        3783|          20491|\n",
            "| excellent|         30|                      1|          37|                        4424|          20491|\n",
            "|    really|         32|                      1|          82|                        4883|          20491|\n",
            "| cringeshe|         44|                      1|          36|                        null|           null|\n",
            "|      mind|         46|                      1|          68|                        null|           null|\n",
            "|    pretty|         51|                      1|          84|                        null|           null|\n",
            "|     steer|         52|                      1|          64|                        null|           null|\n",
            "|     tacky|         54|                      1|         125|                        null|           null|\n",
            "|   staying|         58|                      1|          36|                        null|           null|\n",
            "|       etc|         63|                      1|          96|                        null|           null|\n",
            "|   include|         67|                      1|         214|                        null|           null|\n",
            "|    street|         70|                      1|          32|                        2769|          20491|\n",
            "| available|         74|                      1|          36|                        null|           null|\n",
            "|     hangs|         76|                      1|          58|                        null|           null|\n",
            "|  requests|         78|                      1|          43|                        null|           null|\n",
            "|       bed|         80|                      1|          98|                        3783|          20491|\n",
            "|    mishap|         82|                      1|         108|                        null|           null|\n",
            "|    luxury|         83|                      1|          99|                        null|           null|\n",
            "|   pillows|         84|                      1|          45|                        null|           null|\n",
            "|   eyemask|         84|                      1|          45|                        null|           null|\n",
            "|nonsmoking|         87|                      1|          93|                        null|           null|\n",
            "|   science|         93|                      1|          68|                        null|           null|\n",
            "| microwave|         98|                      1|         125|                        null|           null|\n",
            "+----------+-----------+-----------------------+------------+----------------------------+---------------+\n",
            "only showing top 33 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf_idf_table = (\n",
        "    tf_table\n",
        "    .join(\n",
        "        (\n",
        "            tf_table\n",
        "            .groupBy('Document_ID')\n",
        "            .agg(\n",
        "                {\"Token_in_document_count\": \"sum\"}\n",
        "            )\n",
        "            .withColumnRenamed(\n",
        "                'sum(Token_in_document_count)',\n",
        "                'Tokens_count'\n",
        "            )\n",
        "        ),\n",
        "        on='Document_ID',\n",
        "        how='left'\n",
        "    )\n",
        "    .join(\n",
        "        idf_table,\n",
        "        on='Token',\n",
        "        how='left'\n",
        "    )\n",
        ")\n",
        "\n",
        "tf_idf_table.show(n=33, truncate=True, vertical=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ef6033",
      "metadata": {
        "id": "43ef6033",
        "outputId": "2420e160-ffe4-44ac-c91c-81962a8be761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+--------------------+\n",
            "|      Token|Document_ID|              TF-IDF|\n",
            "+-----------+-----------+--------------------+\n",
            "|       room|          0|0.018969917298355492|\n",
            "|     better|          1|   0.021885964343023|\n",
            "|         nt|         10| 0.05861144808162943|\n",
            "|      clean|         12|0.016919882906726882|\n",
            "|       stay|         15|0.009772311740784861|\n",
            "|       desk|         16| 0.06791032495372712|\n",
            "|        bed|         19|0.016141640469173452|\n",
            "|  excellent|         30| 0.05977208382864487|\n",
            "|     really|         32|0.025233545234842725|\n",
            "|     street|         70| 0.09023604479773865|\n",
            "|        bed|         80|0.024871303171889705|\n",
            "|        day|        116|0.025712667815178728|\n",
            "|       just|        125| 0.02066662782967244|\n",
            "|     little|        133|0.027726300229127476|\n",
            "|     hotels|        146| 0.01870759696543231|\n",
            "|        did|        153|0.007976294401516069|\n",
            "|    walking|        173| 0.05654406021356884|\n",
            "|         no|        176|  0.0078983576505205|\n",
            "|   bathroom|        189| 0.10309538426972249|\n",
            "|        day|        207|0.020512352976153815|\n",
            "|    service|        214|0.024887293533810112|\n",
            "|comfortable|        247|0.040288596114607264|\n",
            "|      night|        260|0.016950482953334785|\n",
            "|       area|        261|0.042650223028457154|\n",
            "|       trip|        264|0.022613732682515198|\n",
            "|       nice|        275| 0.12212494169886676|\n",
            "|      place|        278| 0.04747749713703397|\n",
            "|      staff|        290|  0.0338713531314212|\n",
            "|restaurants|        301|0.040157322354430085|\n",
            "|   location|        303|0.044207642772044656|\n",
            "|       desk|        307| 0.08253716417452989|\n",
            "|        not|        324|0.005294577867903761|\n",
            "|     little|        329|0.017328937643204673|\n",
            "+-----------+-----------+--------------------+\n",
            "only showing top 33 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf_idf_table = (tf_idf_table.na\n",
        "    .drop(\n",
        "        subset=['Token_in_all_documents_count']\n",
        "    )\n",
        "    .withColumn(\n",
        "        'TF',\n",
        "        F.col('Token_in_document_count') / F.col('Tokens_count')\n",
        "    )\n",
        "    .withColumn(\n",
        "        'IDF',\n",
        "        F.log2(F.col('Documents_count') / F.col('Token_in_all_documents_count'))\n",
        "    )\n",
        "    .withColumn(\n",
        "        'TF-IDF',\n",
        "        F.col('TF') * F.col('IDF')\n",
        "    )\n",
        ")\n",
        "\n",
        "(\n",
        "    tf_idf_table\n",
        "    .select(['Token', 'Document_ID', 'TF-IDF'])\n",
        "    .show(n=33, truncate=True, vertical=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249bfd8f",
      "metadata": {
        "id": "249bfd8f",
        "outputId": "32015e9f-c293-4332-d056-bef9eb50cb87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "444239"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf_table.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ee77b4",
      "metadata": {
        "id": "86ee77b4",
        "outputId": "493211f5-79fb-460f-86ec-0bad6eba93b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+-----------------+-------------------+\n",
            "| Token|                   0|                1|                 10|\n",
            "+------+--------------------+-----------------+-------------------+\n",
            "|  room|0.018969917298355492|             null|               null|\n",
            "|better|                null|0.021885964343023|               null|\n",
            "|    nt|                null|             null|0.05861144808162943|\n",
            "+------+--------------------+-----------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    tf_idf_table\n",
        "    .limit(3)\n",
        "    .groupBy('Token')\n",
        "    .pivot('Document_ID')\n",
        "    .agg(\n",
        "        F.first(F.col('TF-IDF'))\n",
        "    )\n",
        "    .show()\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8rc1"
    },
    "colab": {
      "name": "Preprocesamiento (5) - PySpark.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}